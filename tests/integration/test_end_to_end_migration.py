"""
æ•´åˆæ¸¬è©¦: ç«¯åˆ°ç«¯é·ç§»æµç¨‹

é€™äº›æ¸¬è©¦é©—è­‰å®Œæ•´çš„é·ç§»ç®¡ç·šæ˜¯å¦æ­£å¸¸é‹ä½œã€‚
æ ¹æ“š TDD åŸå‰‡,é€™äº›æ¸¬è©¦å¿…é ˆå…ˆå¯«ä¸”å¿…é ˆå¤±æ•— (å› ç‚ºç®¡ç·šå°šæœªå¯¦ä½œ)ã€‚
"""

import json
import subprocess
from pathlib import Path
from typing import Any, Dict, List

import pytest


# ===== Test Fixtures =====

@pytest.fixture
def specs_dir() -> Path:
    """è¦æ ¼ç›®éŒ„"""
    return Path("specs/004-complete-module-migration")


@pytest.fixture
def usage_report_path(specs_dir: Path) -> Path:
    """ä½¿ç”¨åˆ†æå ±å‘Šè·¯å¾‘"""
    return specs_dir / "FUNCTION_USAGE_REPORT.json"


@pytest.fixture
def mapping_path(specs_dir: Path) -> Path:
    """é·ç§»å°æ‡‰è¡¨è·¯å¾‘"""
    return specs_dir / "MIGRATION_MAPPING.json"


@pytest.fixture
def deletion_log_path(specs_dir: Path) -> Path:
    """åˆªé™¤æ—¥èªŒè·¯å¾‘"""
    return specs_dir / "DELETION_LOG.md"


# ===== Integration Test 1: Analysis to Deletion Flow =====

def test_analysis_to_deletion_flow(
    usage_report_path: Path,
    deletion_log_path: Path
):
    """
    Integration Test 1: æ¸¬è©¦åˆ†æ â†’ åˆªé™¤æµç¨‹

    é©—è­‰:
    1. FUNCTION_USAGE_REPORT.json å­˜åœ¨ä¸”æœ‰æ•ˆ
    2. å¯å¾å ±å‘Šä¸­è­˜åˆ¥ test_only å’Œ unused å‡½æ•¸
    3. DELETION_LOG.md è¨˜éŒ„åˆªé™¤ç†ç”±
    """
    # æª¢æŸ¥ä½¿ç”¨åˆ†æå ±å‘Šå­˜åœ¨
    if not usage_report_path.exists():
        pytest.fail(
            f"ä½¿ç”¨åˆ†æå ±å‘Šä¸å­˜åœ¨: {usage_report_path}\n"
            f"è«‹å…ˆåŸ·è¡Œ: python scripts/analyze_function_usage.py"
        )

    # è¼‰å…¥å ±å‘Š
    with open(usage_report_path, "r", encoding="utf-8") as f:
        report = json.load(f)

    # è­˜åˆ¥å¾…åˆªé™¤å‡½æ•¸
    to_delete = [
        item for item in report
        if item["category"] in ["test_only", "unused"]
    ]

    assert len(to_delete) > 0, (
        f"å ±å‘Šä¸­æ²’æœ‰ test_only æˆ– unused å‡½æ•¸\n"
        f"é€™ä¸ç¬¦åˆé æœŸ (æ‡‰æœ‰ ~10-20 å€‹å¾…åˆªé™¤å‡½æ•¸)"
    )

    # æª¢æŸ¥åˆªé™¤æ—¥èªŒ (å¦‚æœå­˜åœ¨)
    if deletion_log_path.exists():
        log_content = deletion_log_path.read_text(encoding="utf-8")

        # é©—è­‰æ—¥èªŒåŒ…å«åˆªé™¤è¨˜éŒ„
        for item in to_delete[:3]:  # æª¢æŸ¥å‰ 3 å€‹
            func_name = item["function_name"]
            assert func_name in log_content, (
                f"åˆªé™¤æ—¥èªŒæœªè¨˜éŒ„å‡½æ•¸: {func_name}"
            )

    print(f"\nåˆ†æ â†’ åˆªé™¤æµç¨‹é©—è­‰:")
    print(f"  åˆ†æå ±å‘Š: âœ“ ({len(report)} å€‹å‡½æ•¸)")
    print(f"  å¾…åˆªé™¤å‡½æ•¸: {len(to_delete)}")
    print(f"  åˆªé™¤æ—¥èªŒ: {'âœ“' if deletion_log_path.exists() else 'å¾…ç”¢ç”Ÿ'}")


# ===== Integration Test 2: Migration to Re-export Flow =====

def test_migration_to_reexport_flow(
    mapping_path: Path,
    usage_report_path: Path
):
    """
    Integration Test 2: æ¸¬è©¦é·ç§» â†’ re-export æµç¨‹

    é©—è­‰:
    1. MIGRATION_MAPPING.json å­˜åœ¨ä¸”å°æ‡‰æ‰€æœ‰ production å‡½æ•¸
    2. utils.py åŒ…å«æ‰€æœ‰é·ç§»å‡½æ•¸çš„ re-export
    3. Re-export å‡½æ•¸å¯æ­£å¸¸ import
    """
    # æª¢æŸ¥é·ç§»å°æ‡‰è¡¨å­˜åœ¨
    if not mapping_path.exists():
        pytest.fail(
            f"é·ç§»å°æ‡‰è¡¨ä¸å­˜åœ¨: {mapping_path}\n"
            f"è«‹å…ˆåŸ·è¡Œé·ç§»å°æ‡‰ç”Ÿæˆå·¥å…·"
        )

    # è¼‰å…¥å°æ‡‰è¡¨
    with open(mapping_path, "r", encoding="utf-8") as f:
        mapping = json.load(f)

    assert len(mapping) > 0, "é·ç§»å°æ‡‰è¡¨ç‚ºç©º"

    # è¼‰å…¥ä½¿ç”¨å ±å‘Š (é©—è­‰å®Œæ•´æ€§)
    if usage_report_path.exists():
        with open(usage_report_path, "r", encoding="utf-8") as f:
            report = json.load(f)

        production_funcs = [
            item["function_name"]
            for item in report
            if item["category"] == "production"
        ]

        mapped_funcs = [item["function_name"] for item in mapping]

        # é©—è­‰å°æ‡‰å®Œæ•´æ€§
        missing = set(production_funcs) - set(mapped_funcs)
        assert not missing, (
            f"éƒ¨åˆ† production å‡½æ•¸ç¼ºå°‘é·ç§»å°æ‡‰: {missing}"
        )

    # æª¢æŸ¥ utils.py æ˜¯å¦å·²é‡å¯«ç‚º re-export å±¤
    utils_py = Path("spellvid/utils.py")
    utils_content = utils_py.read_text(encoding="utf-8")
    utils_lines = len(utils_content.splitlines())

    if utils_lines < 200:  # å·²é‡å¯«ç‚º re-export å±¤
        # é©—è­‰ re-export åŒ…å«æ‰€æœ‰é·ç§»å‡½æ•¸
        for item in mapping[:5]:  # æª¢æŸ¥å‰ 5 å€‹
            func_name = item["function_name"]
            # ç°¡å–®æª¢æŸ¥å‡½æ•¸åæ˜¯å¦å‡ºç¾åœ¨æª”æ¡ˆä¸­
            assert func_name in utils_content, (
                f"utils.py ä¸­æ‰¾ä¸åˆ° re-export: {func_name}"
            )

    print(f"\né·ç§» â†’ Re-export æµç¨‹é©—è­‰:")
    print(f"  é·ç§»å°æ‡‰è¡¨: âœ“ ({len(mapping)} å€‹å‡½æ•¸)")
    print(f"  utils.py è¡Œæ•¸: {utils_lines}")
    print(f"  Re-export å±¤: {'âœ“ å·²å»ºç«‹' if utils_lines < 200 else 'å¾…å»ºç«‹'}")


# ===== Integration Test 3: Full Pipeline with Validation =====

def test_full_pipeline_with_validation(specs_dir: Path):
    """
    Integration Test 3: æ¸¬è©¦å®Œæ•´æµç¨‹ + é©—è­‰

    æ¨¡æ“¬å®Œæ•´é·ç§»ç®¡ç·š:
    1. å‡½æ•¸ä½¿ç”¨åˆ†æ â†’ FUNCTION_USAGE_REPORT.json
    2. å†—é¤˜å‡½æ•¸åˆªé™¤ â†’ DELETION_LOG.md
    3. æœ‰æ•ˆå‡½æ•¸é·ç§» â†’ MIGRATION_MAPPING.json
    4. Re-export å±¤å»ºç«‹ â†’ utils.py (80-120 è¡Œ)
    5. æ¸¬è©¦é©—è­‰ â†’ æ‰€æœ‰æ¸¬è©¦é€šé

    æ­¤æ¸¬è©¦é©—è­‰æ‰€æœ‰ä¸­é–“ç”¢ç‰©å­˜åœ¨ä¸”ä¸€è‡´ã€‚
    """
    expected_artifacts = [
        "FUNCTION_USAGE_REPORT.json",
        "MIGRATION_MAPPING.json",
    ]

    optional_artifacts = [
        "DELETION_LOG.md",
        "MANUAL_REVIEW_LOG.md",
    ]

    # æª¢æŸ¥å¿…è¦ç”¢ç‰©
    missing = []
    for artifact in expected_artifacts:
        if not (specs_dir / artifact).exists():
            missing.append(artifact)

    if missing:
        pytest.fail(
            f"é·ç§»ç®¡ç·šä¸­é–“ç”¢ç‰©ç¼ºå¤±:\n" +
            "\n".join(f"  - {a}" for a in missing) +
            f"\n\né€™æ˜¯é æœŸçš„å¤±æ•— (ç®¡ç·šå°šæœªåŸ·è¡Œ)"
        )

    # è¼‰å…¥ä¸¦é©—è­‰ä¸€è‡´æ€§
    usage_report_path = specs_dir / "FUNCTION_USAGE_REPORT.json"
    mapping_path = specs_dir / "MIGRATION_MAPPING.json"

    with open(usage_report_path, "r", encoding="utf-8") as f:
        report = json.load(f)

    with open(mapping_path, "r", encoding="utf-8") as f:
        mapping = json.load(f)

    # é©—è­‰æ•¸é‡ä¸€è‡´æ€§
    production_count = sum(
        1 for item in report if item["category"] == "production"
    )

    assert len(mapping) == production_count, (
        f"é·ç§»å°æ‡‰è¡¨æ•¸é‡ä¸ä¸€è‡´:\n"
        f"  Production å‡½æ•¸: {production_count}\n"
        f"  é·ç§»å°æ‡‰: {len(mapping)}"
    )

    # é©—è­‰ utils.py ç‹€æ…‹
    utils_py = Path("spellvid/utils.py")
    utils_lines = len(utils_py.read_text(encoding="utf-8").splitlines())

    reduction_rate = (3714 - utils_lines) / 3714 * 100

    # æª¢æŸ¥æ¸¬è©¦ç‹€æ…‹ (å¯é¸)
    test_result = None
    try:
        result = subprocess.run(
            ["python", "-m", "pytest", "tests/", "-q", "--tb=no"],
            capture_output=True,
            text=True,
            timeout=300,  # 5 åˆ†é˜è¶…æ™‚
        )
        test_result = result.returncode == 0
    except (subprocess.TimeoutExpired, FileNotFoundError):
        test_result = None

    print(f"\nå®Œæ•´ç®¡ç·šé©—è­‰:")
    print(f"  ä½¿ç”¨åˆ†æå ±å‘Š: âœ“ ({len(report)} å€‹å‡½æ•¸)")
    print(f"  é·ç§»å°æ‡‰è¡¨: âœ“ ({len(mapping)} å€‹å‡½æ•¸)")
    print(f"  utils.py è¡Œæ•¸: {utils_lines} (ç¸®æ¸› {reduction_rate:.1f}%)")
    print(f"  æ¸¬è©¦ç‹€æ…‹: {'âœ“ é€šé' if test_result else 'å¾…é©—è­‰'}")

    # æœ€çµ‚é©—è­‰
    if utils_lines <= 120 and reduction_rate >= 95.0:
        print(f"\nğŸ‰ é·ç§»ç®¡ç·šç›®æ¨™é”æˆ!")
        print(f"  âœ“ utils.py ç¸®æ¸›è‡³ {utils_lines} è¡Œ")
        print(f"  âœ“ ç¸®æ¸›ç‡ {reduction_rate:.2f}% (â‰¥95%)")
    else:
        print(f"\nâ³ é·ç§»ç®¡ç·šé€²è¡Œä¸­...")
