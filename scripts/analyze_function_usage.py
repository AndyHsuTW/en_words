#!/usr/bin/env python3
"""
å‡½æ•¸ä½¿ç”¨åˆ†æžå·¥å…· - åˆ†æž utils.py ä¸­æ¯å€‹å‡½æ•¸çš„ä½¿ç”¨æƒ…æ³

ä½¿ç”¨å¤šå·¥å…·äº¤å‰é©—è­‰ (grep + AST) è­˜åˆ¥å‡½æ•¸åˆ†é¡ž:
- production: è¢«ç”Ÿç”¢ä»£ç¢¼ä½¿ç”¨ (spellvid/*.py éžæ¸¬è©¦, scripts/*.py)
- test_only: åƒ…è¢«æ¸¬è©¦ä½¿ç”¨ (tests/*.py)
- unused: ç„¡ä»»ä½•å¼•ç”¨
"""

import argparse
import ast
import json
from pathlib import Path
from typing import Dict, List


# ===== Data Structures =====

class FileReference:
    """æª”æ¡ˆå¼•ç”¨ä½ç½®"""

    def __init__(self, filepath: str, line_number: int, context: str):
        self.filepath = filepath
        self.line_number = line_number
        self.context = context

    def to_dict(self):
        return {
            "filepath": self.filepath,
            "line_number": self.line_number,
            "context": self.context,
        }


class FunctionUsageReport:
    """å‡½æ•¸ä½¿ç”¨å ±å‘Š"""

    def __init__(self, function_name: str):
        self.function_name = function_name
        self.references: List[FileReference] = []
        self.category = "unused"  # production | test_only | unused
        self.analysis_confidence = 0.0
        self.notes = ""

    @property
    def call_count(self) -> int:
        return len(self.references)

    def to_dict(self):
        return {
            "function_name": self.function_name,
            "category": self.category,
            "references": [ref.to_dict() for ref in self.references],
            "call_count": self.call_count,
            "analysis_confidence": self.analysis_confidence,
            "notes": self.notes,
        }


# ===== Tool 1: grep æŽƒæ =====


def grep_scan_references(
    function_name: str, repo_root: Path, verbose: bool = False
) -> List[FileReference]:
    """
    ä½¿ç”¨ grep æŽƒæå‡½æ•¸åç¨±å‡ºç¾ä½ç½®

    Returns:
        List[FileReference]: å¼•ç”¨ä½ç½®æ¸…å–®
    """
    references = []

    # ä½¿ç”¨ Python è‡ªå·±æŽƒæ (è·¨å¹³å°ç›¸å®¹)
    for py_file in repo_root.rglob("*.py"):
        # æŽ’é™¤è·¯å¾‘
        rel_path = py_file.relative_to(repo_root)
        rel_str = str(rel_path).replace("\\", "/")

        # è·³éŽæŽ’é™¤çš„è·¯å¾‘
        if any(
            exclude in rel_str
            for exclude in ["__pycache__", ".venv", "venv", ".git", ".bak"]
        ):
            continue

        try:
            content = py_file.read_text(encoding="utf-8")
            lines = content.splitlines()

            for i, line in enumerate(lines, start=1):
                # æª¢æŸ¥å‡½æ•¸åç¨±æ˜¯å¦å‡ºç¾ (ç°¡å–®å­—ä¸²åŒ¹é…)
                if function_name in line:
                    # æå–ä¸Šä¸‹æ–‡ (å‰å¾Œå„ 1 è¡Œ)
                    context_lines = []
                    if i > 1:
                        context_lines.append(lines[i - 2])
                    context_lines.append(line)
                    if i < len(lines):
                        context_lines.append(lines[i])

                    context = "\n".join(context_lines)

                    references.append(FileReference(rel_str, i, context))

                    if verbose:
                        print(f"  Found in {rel_str}:{i}")

        except (UnicodeDecodeError, PermissionError):
            continue

    return references


# ===== Tool 3: å‘¼å«åœ–åˆ†æž =====


def build_call_graph(utils_py_path: Path) -> Dict[str, List[str]]:
    """
    å»ºç«‹ utils.py å…§éƒ¨çš„å‘¼å«åœ–

    Returns:
        Dict[str, List[str]]: {caller: [callee1, callee2, ...]}
    """
    call_graph = {}

    try:
        content = utils_py_path.read_text(encoding="utf-8")
        tree = ast.parse(content)

        # æå–æ‰€æœ‰å‡½æ•¸åç¨±
        all_functions = {
            node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)
        }

        # åˆ†æžæ¯å€‹å‡½æ•¸çš„å‘¼å«
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                func_name = node.name
                callees = []

                # æŽƒæå‡½æ•¸é«”ä¸­çš„ Call nodes
                for child in ast.walk(node):
                    if isinstance(child, ast.Call):
                        # æå–è¢«å‘¼å«çš„å‡½æ•¸åç¨±
                        if isinstance(child.func, ast.Name):
                            callee = child.func.id
                            if callee in all_functions:
                                callees.append(callee)

                call_graph[func_name] = callees

    except SyntaxError:
        pass

    return call_graph


# ===== åˆ†é¡žé‚è¼¯ =====


def classify_function(
    function_name: str, references: List[FileReference], utils_filepath: str
) -> str:
    """
    æ ¹æ“šå¼•ç”¨ä½ç½®åˆ†é¡žå‡½æ•¸

    Returns:
        "production" | "test_only" | "unused"
    """
    if len(references) == 0:
        return "unused"

    has_production = False
    has_test = False

    for ref in references:
        filepath = ref.filepath

        # æŽ’é™¤ utils.py è‡ªèº«
        if filepath == utils_filepath or filepath.replace("\\", "/") == utils_filepath:
            continue

        # æª¢æŸ¥æ˜¯å¦ç‚ºç”Ÿç”¢ä»£ç¢¼
        if filepath.startswith("spellvid/") or filepath.startswith("spellvid\\"):
            if "tests" not in filepath:
                has_production = True

        if filepath.startswith("scripts/") or filepath.startswith("scripts\\"):
            has_production = True

        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¸¬è©¦ä»£ç¢¼
        if filepath.startswith("tests/") or filepath.startswith("tests\\"):
            has_test = True

    # åˆ†é¡žæ±ºç­–
    if has_production:
        return "production"
    elif has_test:
        return "test_only"
    else:
        return "unused"


# ===== ä¸»å‡½æ•¸ =====


def extract_functions_from_utils(utils_py_path: Path) -> List[str]:
    """æå– utils.py ä¸­æ‰€æœ‰å‡½æ•¸åç¨±"""
    content = utils_py_path.read_text(encoding="utf-8")
    tree = ast.parse(content)

    functions = [
        node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)
    ]

    return functions


def main():
    parser = argparse.ArgumentParser(description="åˆ†æž utils.py å‡½æ•¸ä½¿ç”¨æƒ…æ³")
    parser.add_argument("--input", default="spellvid/utils.py", help="è¦åˆ†æžçš„æª”æ¡ˆ")
    parser.add_argument(
        "--output",
        default="specs/004-complete-module-migration/FUNCTION_USAGE_REPORT.json",
        help="è¼¸å‡ºçš„ JSON å ±å‘Š",
    )
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°è¼¸å‡º")

    args = parser.parse_args()

    utils_py_path = Path(args.input)
    output_path = Path(args.output)
    repo_root = Path(".")

    print(f"ðŸ” åˆ†æžæª”æ¡ˆ: {utils_py_path}")
    print(f"ðŸ“Š è¼¸å‡ºå ±å‘Š: {output_path}")
    print()

    # æå–æ‰€æœ‰å‡½æ•¸
    print("Step 1: æå–å‡½æ•¸å®šç¾©...")
    functions = extract_functions_from_utils(utils_py_path)
    print(f"  æ‰¾åˆ° {len(functions)} å€‹å‡½æ•¸")

    # å»ºç«‹å‘¼å«åœ–
    print("\nStep 2: å»ºç«‹å…§éƒ¨å‘¼å«åœ–...")
    call_graph = build_call_graph(utils_py_path)
    print(f"  å‘¼å«é—œä¿‚: {sum(len(v) for v in call_graph.values())} å€‹")

    # åˆ†æžæ¯å€‹å‡½æ•¸
    print("\nStep 3: æŽƒæå¼•ç”¨ä½ç½® (grep)...")
    reports = []

    for i, func_name in enumerate(functions, 1):
        if args.verbose:
            print(f"\n[{i}/{len(functions)}] {func_name}")
        else:
            if i % 10 == 0:
                print(f"  é€²åº¦: {i}/{len(functions)}")

        # ä½¿ç”¨ grep æŽƒæ
        references = grep_scan_references(func_name, repo_root, args.verbose)

        # åˆ†é¡ž
        category = classify_function(func_name, references, args.input)

        # å»ºç«‹å ±å‘Š
        report = FunctionUsageReport(func_name)
        report.references = references
        report.category = category

        # è¨ˆç®—ä¿¡å¿ƒåº¦ (grepæŽƒæ + åˆ†é¡žé‚è¼¯)
        # - åŸºç¤Ž grep æŽƒæ: 0.6
        # - æœ‰ production å¼•ç”¨: +0.2
        # - å¼•ç”¨æ•¸ >= 5: +0.2
        base_confidence = 0.6
        if category == "production":
            base_confidence += 0.2
        if len(references) >= 5:
            base_confidence += 0.2
        report.analysis_confidence = min(base_confidence, 1.0)

        # æ·»åŠ è¨»è¨˜
        if category == "unused" and len(references) > 0:
            report.notes = "åƒ…åœ¨ utils.py å…§éƒ¨è¢«å¼•ç”¨"
        elif category == "test_only":
            report.notes = "åƒ…è¢«æ¸¬è©¦ä½¿ç”¨,ç”Ÿç”¢ä»£ç¢¼æœªå¼•ç”¨"
        elif report.analysis_confidence < 0.8:
            report.notes = f"ä½Žä¿¡å¿ƒåˆ†é¡ž (refs={len(references)}), éœ€äººå·¥å¯©æŸ¥"

        reports.append(report)

    # çµ±è¨ˆçµæžœ
    print("\n" + "=" * 60)
    print("åˆ†æžå®Œæˆ!")
    print("=" * 60)

    categories = {"production": 0, "test_only": 0, "unused": 0}
    for report in reports:
        categories[report.category] += 1

    print(f"\nåˆ†é¡žçµ±è¨ˆ:")
    print(f"  production: {categories['production']} å€‹")
    print(f"  test_only:  {categories['test_only']} å€‹")
    print(f"  unused:     {categories['unused']} å€‹")

    # è¼¸å‡º JSON
    output_path.parent.mkdir(parents=True, exist_ok=True)

    output_data = [report.to_dict() for report in reports]

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… å ±å‘Šå·²å„²å­˜: {output_path}")
    print(f"ðŸ“„ ç¸½è¨ˆ: {len(reports)} å€‹å‡½æ•¸")


if __name__ == "__main__":
    main()
